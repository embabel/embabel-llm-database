{
  "model_id": "gemma-3-1b-it",
  "name": "Gemma 3 1B",
  "organization_id": "google",
  "fine_tuned_from_model_id": null,
  "description": "The Gemma 3 1B model is a lightweight, 1-billion-parameter language model by Google, optimized for efficiency on resource-limited devices. At 529MB, it processes text at 2,585 tokens/second with a context window of 128,000 tokens. It supports 35+ languages but handles text-only input, unlike larger multimodal Gemma models. This balance of speed and efficiency makes it ideal for fast text processing on mobile and low-power devices.",
  "release_date": "2025-03-12",
  "announcement_date": "2025-03-12",
  "license_id": "gemma",
  "multimodal": false,
  "knowledge_cutoff": null,
  "param_count": 1000000000,
  "training_tokens": 2000000000000,
  "available_in_zeroeval": true,
  "source_api_ref": "https://huggingface.co/google/gemma-3-1b-it",
  "source_playground": "https://huggingface.co/chat/models/google/gemma-3-1b-it",
  "source_paper": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf",
  "source_scorecard_blog_link": "https://huggingface.co/blog/gemma3",
  "source_repo_link": null,
  "source_weights_link": "https://huggingface.co/google/gemma-3-1b-it",
  "created_at": "2025-07-19T19:49:05.527185+00:00",
  "updated_at": "2025-07-19T19:49:05.527185+00:00",
  "model_family_id": null
}