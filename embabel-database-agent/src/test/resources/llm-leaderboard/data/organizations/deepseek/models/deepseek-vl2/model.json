{
  "model_id": "deepseek-vl2",
  "name": "DeepSeek VL2",
  "organization_id": "deepseek",
  "fine_tuned_from_model_id": null,
  "description": "An advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL. DeepSeek-VL2 demonstrates superior capabilities across various tasks, including but not limited to visual question answering, optical character recognition, document/table/chart understanding, and visual grounding.",
  "release_date": "2024-12-13",
  "announcement_date": "2024-12-13",
  "license_id": "deepseek",
  "multimodal": true,
  "knowledge_cutoff": null,
  "param_count": 27000000000,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": "https://www.deepseek.com/",
  "source_playground": "https://huggingface.co/deepseek-ai/deepseek-vl2",
  "source_paper": "https://arxiv.org/pdf/2412.10302",
  "source_scorecard_blog_link": null,
  "source_repo_link": "https://github.com/deepseek-ai/DeepSeek-VL2?tab=readme-ov-file",
  "source_weights_link": "https://huggingface.co/deepseek-ai/deepseek-vl2",
  "created_at": "2025-07-19T19:49:05.658016+00:00",
  "updated_at": "2025-07-19T19:49:05.658016+00:00",
  "model_family_id": null
}