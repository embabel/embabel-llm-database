{
  "model_id": "llama-3.3-70b-instruct",
  "name": "Llama 3.3 70B Instruct",
  "organization_id": "meta",
  "fine_tuned_from_model_id": null,
  "description": "Llama 3.3 is a multilingual large language model optimized for dialogue use cases across multiple languages. It is a pretrained and instruction-tuned generative model with 70 billion parameters, outperforming many open-source and closed chat models on common industry benchmarks. Llama 3.3 supports a context length of 128,000 tokens and is designed for commercial and research use in multiple languages.",
  "release_date": "2024-12-06",
  "announcement_date": "2024-12-06",
  "license_id": "llama_3_3_community_license_agreement",
  "multimodal": false,
  "knowledge_cutoff": null,
  "param_count": 70000000000,
  "training_tokens": 15000000000000,
  "available_in_zeroeval": true,
  "source_api_ref": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
  "source_playground": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
  "source_paper": null,
  "source_scorecard_blog_link": null,
  "source_repo_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
  "source_weights_link": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
  "created_at": "2025-07-19T19:49:05.603412+00:00",
  "updated_at": "2025-07-19T19:49:05.603412+00:00",
  "model_family_id": null
}