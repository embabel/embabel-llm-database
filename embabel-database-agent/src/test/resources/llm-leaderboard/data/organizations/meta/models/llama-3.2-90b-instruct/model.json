{
  "model_id": "llama-3.2-90b-instruct",
  "name": "Llama 3.2 90B Instruct",
  "organization_id": "meta",
  "fine_tuned_from_model_id": null,
  "description": "Llama 3.2 90B is a large multimodal language model optimized for visual recognition, image reasoning, and captioning tasks. It supports a context length of 128,000 tokens and is designed for deployment on edge and mobile devices, offering state-of-the-art performance in image understanding and generative tasks.",
  "release_date": "2024-09-25",
  "announcement_date": "2024-09-25",
  "license_id": "llama3_2",
  "multimodal": true,
  "knowledge_cutoff": null,
  "param_count": 90000000000,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct",
  "source_playground": null,
  "source_paper": null,
  "source_scorecard_blog_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
  "source_repo_link": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct",
  "source_weights_link": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct",
  "created_at": "2025-07-19T19:49:05.579590+00:00",
  "updated_at": "2025-07-19T19:49:05.579590+00:00",
  "model_family_id": null
}