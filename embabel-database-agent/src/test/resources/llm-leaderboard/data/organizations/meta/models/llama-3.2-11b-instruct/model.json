{
  "model_id": "llama-3.2-11b-instruct",
  "name": "Llama 3.2 11B Instruct",
  "organization_id": "meta",
  "fine_tuned_from_model_id": null,
  "description": "Llama 3.2 11B Vision Instruct is an instruction-tuned multimodal large language model optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. It accepts text and images as input and generates text as output.",
  "release_date": "2024-09-25",
  "announcement_date": "2024-09-25",
  "license_id": "llama_3_2_community_license",
  "multimodal": true,
  "knowledge_cutoff": "2023-12-31",
  "param_count": 10600000000,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
  "source_playground": null,
  "source_paper": null,
  "source_scorecard_blog_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
  "source_repo_link": "https://github.com/facebookresearch/llama",
  "source_weights_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
  "created_at": "2025-07-19T19:49:05.588479+00:00",
  "updated_at": "2025-07-19T19:49:05.588479+00:00",
  "model_family_id": null
}