{
  "model_id": "llama-4-scout",
  "name": "Llama 4 Scout",
  "organization_id": "meta",
  "fine_tuned_from_model_id": null,
  "description": "Llama 4 Scout is a natively multimodal model capable of processing both text and images. It features a 17 billion activated parameter (109B total) mixture-of-experts (MoE) architecture with 16 experts, supporting a wide range of multimodal tasks such as conversational interaction, image analysis, and code generation. The model includes a 10 million token context window.",
  "release_date": "2025-04-05",
  "announcement_date": "2025-04-05",
  "license_id": "llama_4_community_license_agreement",
  "multimodal": true,
  "knowledge_cutoff": null,
  "param_count": 109000000000,
  "training_tokens": 40000000000000,
  "available_in_zeroeval": true,
  "source_api_ref": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
  "source_playground": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
  "source_paper": null,
  "source_scorecard_blog_link": null,
  "source_repo_link": "https://github.com/meta-llama/llama-models/tree/main/models/llama4",
  "source_weights_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
  "created_at": "2025-07-19T19:49:05.599841+00:00",
  "updated_at": "2025-07-19T19:49:05.599841+00:00",
  "model_family_id": null
}