[
  {
    "model_benchmark_id": 17,
    "benchmark_id": "arc-c",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.786,
    "normalized_score": 0.786,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.120164+00:00",
    "updated_at": "2025-07-19T19:56:11.120164+00:00",
    "benchmark_name": "ARC-C"
  },
  {
    "model_benchmark_id": 1583,
    "benchmark_id": "bfcl-v2",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.67,
    "normalized_score": 0.67,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.446368+00:00",
    "updated_at": "2025-07-19T19:56:14.446368+00:00",
    "benchmark_name": "BFCL v2"
  },
  {
    "model_benchmark_id": 293,
    "benchmark_id": "gpqa",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.328,
    "normalized_score": 0.328,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.665423+00:00",
    "updated_at": "2025-07-19T19:56:11.665423+00:00",
    "benchmark_name": "GPQA"
  },
  {
    "model_benchmark_id": 989,
    "benchmark_id": "gsm8k",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.777,
    "normalized_score": 0.777,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "8-shot, em_maj1@1",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.073210+00:00",
    "updated_at": "2025-07-19T19:56:13.073210+00:00",
    "benchmark_name": "GSM8k"
  },
  {
    "model_benchmark_id": 44,
    "benchmark_id": "hellaswag",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.698,
    "normalized_score": 0.698,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.175473+00:00",
    "updated_at": "2025-07-19T19:56:11.175473+00:00",
    "benchmark_name": "HellaSwag"
  },
  {
    "model_benchmark_id": 617,
    "benchmark_id": "ifeval",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.774,
    "normalized_score": 0.774,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "Avg(Prompt/Instruction acc Loose/Strict)",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:12.272319+00:00",
    "updated_at": "2025-07-19T19:56:12.272319+00:00",
    "benchmark_name": "IFEval"
  },
  {
    "model_benchmark_id": 1589,
    "benchmark_id": "infinitebench-en.mc",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.633,
    "normalized_score": 0.633,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, longbook_choice/acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.464298+00:00",
    "updated_at": "2025-07-19T19:56:14.464298+00:00",
    "benchmark_name": "InfiniteBench/En.MC"
  },
  {
    "model_benchmark_id": 1588,
    "benchmark_id": "infinitebench-en.qa",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.198,
    "normalized_score": 0.198,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, longbook_qa/f1",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.460560+00:00",
    "updated_at": "2025-07-19T19:56:14.460560+00:00",
    "benchmark_name": "InfiniteBench/En.QA"
  },
  {
    "model_benchmark_id": 396,
    "benchmark_id": "math",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.48,
    "normalized_score": 0.48,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, final_em",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.849582+00:00",
    "updated_at": "2025-07-19T19:56:11.849582+00:00",
    "benchmark_name": "MATH"
  },
  {
    "model_benchmark_id": 1285,
    "benchmark_id": "mgsm",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.582,
    "normalized_score": 0.582,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "CoT, em",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.692573+00:00",
    "updated_at": "2025-07-19T19:56:13.692573+00:00",
    "benchmark_name": "MGSM"
  },
  {
    "model_benchmark_id": 81,
    "benchmark_id": "mmlu",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.634,
    "normalized_score": 0.634,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "5-shot, macro_avg/acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.252797+00:00",
    "updated_at": "2025-07-19T19:56:11.252797+00:00",
    "benchmark_name": "MMLU"
  },
  {
    "model_benchmark_id": 1569,
    "benchmark_id": "nexus",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.343,
    "normalized_score": 0.343,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, macro_avg/acc",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.401027+00:00",
    "updated_at": "2025-07-19T19:56:14.401027+00:00",
    "benchmark_name": "Nexus"
  },
  {
    "model_benchmark_id": 1590,
    "benchmark_id": "nih-multi-needle",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.847,
    "normalized_score": 0.847,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, recall",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.469424+00:00",
    "updated_at": "2025-07-19T19:56:14.469424+00:00",
    "benchmark_name": "NIH/Multi-needle"
  },
  {
    "model_benchmark_id": 1581,
    "benchmark_id": "open-rewrite",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.401,
    "normalized_score": 0.401,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "0-shot, micro_avg/rougeL",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.438526+00:00",
    "updated_at": "2025-07-19T19:56:14.438526+00:00",
    "benchmark_name": "Open-rewrite"
  },
  {
    "model_benchmark_id": 1582,
    "benchmark_id": "tldr9+-(test)",
    "model_id": "llama-3.2-3b-instruct",
    "score": 0.19,
    "normalized_score": 0.19,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "verified_by_llmstats": false,
    "analysis_method": "1-shot, rougeL",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.443142+00:00",
    "updated_at": "2025-07-19T19:56:14.443142+00:00",
    "benchmark_name": "TLDR9+ (test)"
  }
]