[
  {
    "model_benchmark_id": 702,
    "benchmark_id": "aime-2025",
    "model_id": "claude-opus-4-20250514",
    "score": 0.755,
    "normalized_score": 0.755,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Extended thinking (up to 64K tokens) with parallel test-time compute (multiple attempts, internal scoring model selection). Nucleus sampling (top_p 0.95). Based on footnotes 4, 5 and blog appendix.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:12.468994+00:00",
    "updated_at": "2025-07-19T19:56:12.468994+00:00",
    "benchmark_name": "AIME 2025"
  },
  {
    "model_benchmark_id": 1388,
    "benchmark_id": "arc-agi-v2",
    "model_id": "claude-opus-4-20250514",
    "score": 0.086,
    "normalized_score": 0.086,
    "is_self_reported": false,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "verified_by_llmstats": false,
    "analysis_method": "accuracy",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.923803+00:00",
    "updated_at": "2025-07-19T19:56:13.923803+00:00",
    "benchmark_name": "ARC-AGI v2"
  },
  {
    "model_benchmark_id": 337,
    "benchmark_id": "gpqa",
    "model_id": "claude-opus-4-20250514",
    "score": 0.796,
    "normalized_score": 0.796,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Diamond: Extended thinking (up to 64K tokens) with parallel test-time compute (multiple attempts, internal scoring model selection). Based on footnote 5 and blog appendix.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.734764+00:00",
    "updated_at": "2025-07-19T19:56:11.734764+00:00",
    "benchmark_name": "GPQA"
  },
  {
    "model_benchmark_id": 1480,
    "benchmark_id": "mmmlu",
    "model_id": "claude-opus-4-20250514",
    "score": 0.888,
    "normalized_score": 0.888,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Extended thinking (up to 64K tokens). Average over 14 non-English languages. Based on blog appendix and footnote 3.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.155829+00:00",
    "updated_at": "2025-07-19T19:56:14.155829+00:00",
    "benchmark_name": "MMMLU"
  },
  {
    "model_benchmark_id": 1815,
    "benchmark_id": "mmmu-(validation)",
    "model_id": "claude-opus-4-20250514",
    "score": 0.765,
    "normalized_score": 0.765,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Extended thinking (up to 64K tokens). Based on blog appendix.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:15.120938+00:00",
    "updated_at": "2025-07-19T19:56:15.120938+00:00",
    "benchmark_name": "MMMU (validation)"
  },
  {
    "model_benchmark_id": 1351,
    "benchmark_id": "swe-bench-verified",
    "model_id": "claude-opus-4-20250514",
    "score": 0.725,
    "normalized_score": 0.725,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Parallel test-time compute (multiple attempts, internal scoring model selection). No extended thinking. Based on footnote 5 and SWE-bench methodology for high compute.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:13.843719+00:00",
    "updated_at": "2025-07-19T19:56:13.843719+00:00",
    "benchmark_name": "SWE-Bench Verified"
  },
  {
    "model_benchmark_id": 1775,
    "benchmark_id": "tau-bench-airline",
    "model_id": "claude-opus-4-20250514",
    "score": 0.596,
    "normalized_score": 0.596,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Extended thinking with tool use (up to 64K tokens, prompt addendum, increased max steps). Based on blog appendix and TAU-bench methodology.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:15.005622+00:00",
    "updated_at": "2025-07-19T19:56:15.005622+00:00",
    "benchmark_name": "TAU-bench Airline"
  },
  {
    "model_benchmark_id": 1761,
    "benchmark_id": "tau-bench-retail",
    "model_id": "claude-opus-4-20250514",
    "score": 0.814,
    "normalized_score": 0.814,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Extended thinking with tool use (up to 64K tokens, prompt addendum, increased max steps). Based on blog appendix and TAU-bench methodology.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:14.977090+00:00",
    "updated_at": "2025-07-19T19:56:14.977090+00:00",
    "benchmark_name": "TAU-bench Retail"
  },
  {
    "model_benchmark_id": 655,
    "benchmark_id": "terminal-bench",
    "model_id": "claude-opus-4-20250514",
    "score": 0.392,
    "normalized_score": 0.392,
    "is_self_reported": true,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "verified_by_llmstats": false,
    "analysis_method": "Parallel test-time compute (multiple attempts, internal scoring model selection). No extended thinking. Claude Code as agent framework. Based on footnotes 2 and 5.",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:12.354970+00:00",
    "updated_at": "2025-07-19T19:56:12.354970+00:00",
    "benchmark_name": "Terminal-bench"
  }
]
