{
  "model_id": "magistral-small-2506",
  "name": "Magistral Small 2506",
  "organization_id": "mistral",
  "fine_tuned_from_model_id": null,
  "description": "Building upon Mistral Small 3.1 (2503), with added reasoning capabilities, undergoing SFT from Magistral Medium traces and RL on top, it's a small, efficient reasoning model with 24B parameters. Magistral Small can be deployed locally, fitting within a single RTX 4090 or a 32GB RAM MacBook once quantized.",
  "release_date": "2025-06-10",
  "announcement_date": "2025-06-10",
  "license_id": "apache_2_0",
  "multimodal": false,
  "knowledge_cutoff": "2025-06-01",
  "param_count": 24000000000,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": "https://docs.mistral.ai/api/",
  "source_playground": "https://chat.mistral.ai/",
  "source_paper": "https://arxiv.org/pdf/2506.10910",
  "source_scorecard_blog_link": "https://mistral.ai/news/magistral",
  "source_repo_link": null,
  "source_weights_link": "https://huggingface.co/mistralai/Magistral-Small-2506",
  "created_at": "2025-07-19T19:49:05.777162+00:00",
  "updated_at": "2025-07-19T19:49:05.777162+00:00",
  "model_family_id": null
}