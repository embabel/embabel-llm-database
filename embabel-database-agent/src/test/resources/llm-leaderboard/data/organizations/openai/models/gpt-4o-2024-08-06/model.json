{
  "model_id": "gpt-4o-2024-08-06",
  "name": "GPT-4o",
  "organization_id": "openai",
  "fine_tuned_from_model_id": null,
  "description": "GPT-4o ('o' for 'omni') is a multimodal AI model that accepts text, audio, image, and video inputs, and generates text, audio, and image outputs. It matches GPT-4 Turbo performance on text and code, with improvements in non-English languages, vision, and audio understanding.",
  "release_date": "2024-08-06",
  "announcement_date": "2024-08-06",
  "license_id": "proprietary",
  "multimodal": true,
  "knowledge_cutoff": null,
  "param_count": null,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": "https://platform.openai.com/docs/api-reference",
  "source_playground": "https://chat.openai.com/",
  "source_paper": null,
  "source_scorecard_blog_link": "https://openai.com/index/hello-gpt-4o/",
  "source_repo_link": null,
  "source_weights_link": null,
  "created_at": "2025-07-19T19:49:05.847621+00:00",
  "updated_at": "2025-07-19T19:49:05.847621+00:00",
  "model_family_id": null
}