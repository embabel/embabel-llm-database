{
  "model_id": "gpt-oss-120b",
  "name": "GPT OSS 120B",
  "organization_id": "openai",
  "fine_tuned_from_model_id": null,
  "description": "The gpt-oss-120b model achieves near-parity with OpenAI o4-mini on core reasoning benchmarks, while running efficiently on a single 80 GB GPU. The gpt-oss-20b model delivers similar results to OpenAI o3‑mini on common benchmarks and can run on edge devices with just 16 GB of memory, making it ideal for on-device use cases, local inference, or rapid iteration without costly infrastructure. Both models also perform strongly on tool use, few-shot function calling, CoT reasoning (as seen in results on the Tau-Bench agentic evaluation suite) and HealthBench (even outperforming proprietary models like OpenAI o1 and GPT‑4o).",
  "release_date": "2025-08-05",
  "announcement_date": "2025-08-05",
  "license_id": "apache_2_0",
  "multimodal": true,
  "knowledge_cutoff": null,
  "param_count": 120000000000,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": null,
  "source_playground": "https://gpt-oss.com/",
  "source_paper": null,
  "source_scorecard_blog_link": "https://openai.com/index/gpt-oss-model-card/",
  "source_repo_link": "https://github.com/openai/gpt-oss",
  "source_weights_link": "https://huggingface.co/openai/gpt-oss-120b",
  "created_at": "2025-08-05T19:49:05.852855+00:00",
  "updated_at": "2025-08-05T19:49:05.852855+00:00",
  "model_family_id": null
}
