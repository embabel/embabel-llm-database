{
  "model_id": "qwen-2.5-coder-32b-instruct",
  "name": "Qwen2.5-Coder 32B Instruct",
  "organization_id": "qwen",
  "fine_tuned_from_model_id": "qwen-2.5-32b-instruct",
  "description": "Qwen2.5-Coder is a specialized coding model trained on 5.5 trillion tokens of code data, supporting 92 programming languages with a 128K context window. It excels in code generation, completion, repair, and multi-programming tasks while maintaining strong performance in mathematics and general capabilities.",
  "release_date": "2024-09-19",
  "announcement_date": "2024-09-19",
  "license_id": "apache_2_0",
  "multimodal": false,
  "knowledge_cutoff": null,
  "param_count": 32000000000,
  "training_tokens": 5500000000000,
  "available_in_zeroeval": true,
  "source_api_ref": "https://www.alibabacloud.com/help/en/model-studio/developer-reference/use-qwen-by-calling-api",
  "source_playground": null,
  "source_paper": "https://arxiv.org/abs/2409.12186",
  "source_scorecard_blog_link": "https://qwenlm.github.io/blog/qwen2.5-coder/",
  "source_repo_link": "https://github.com/QwenLM/Qwen2.5-Coder",
  "source_weights_link": "https://huggingface.co/Qwen/Qwen2.5-Coder-32B",
  "created_at": "2025-07-19T19:49:05.882455+00:00",
  "updated_at": "2025-07-19T19:49:05.882455+00:00",
  "model_family_id": null
}