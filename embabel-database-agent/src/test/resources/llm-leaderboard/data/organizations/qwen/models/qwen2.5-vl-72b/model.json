{
  "model_id": "qwen2.5-vl-72b",
  "name": "Qwen2.5 VL 72B Instruct",
  "organization_id": "qwen",
  "fine_tuned_from_model_id": null,
  "description": "Qwen2.5-VL is the new flagship vision-language model of Qwen, significantly improved from Qwen2-VL. It excels at recognizing objects, analyzing text/charts/layouts in images, acting as a visual agent, understanding long videos (over 1 hour) with event pinpointing, performing visual localization (bounding boxes/points), and generating structured outputs from documents.",
  "release_date": "2025-01-26",
  "announcement_date": "2025-01-26",
  "license_id": "tongyi_qianwen",
  "multimodal": true,
  "knowledge_cutoff": null,
  "param_count": 72000000000,
  "training_tokens": null,
  "available_in_zeroeval": true,
  "source_api_ref": null,
  "source_playground": "https://chat.qwen.ai/",
  "source_paper": "https://arxiv.org/pdf/2502.13923",
  "source_scorecard_blog_link": "https://qwenlm.github.io/blog/qwen2.5-vl/",
  "source_repo_link": "https://github.com/QwenLM/Qwen2.5-VL",
  "source_weights_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
  "created_at": "2025-07-19T19:49:05.647509+00:00",
  "updated_at": "2025-07-19T19:49:05.647509+00:00",
  "model_family_id": null
}