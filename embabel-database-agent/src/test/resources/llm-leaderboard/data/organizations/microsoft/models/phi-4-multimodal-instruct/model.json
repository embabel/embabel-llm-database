{
  "model_id": "phi-4-multimodal-instruct",
  "name": "Phi-4-multimodal-instruct",
  "organization_id": "microsoft",
  "fine_tuned_from_model_id": null,
  "description": "Phi-4-multimodal-instruct is a lightweight (5.57B parameters) open multimodal foundation model that leverages research and datasets from Phi-3.5 and 4.0. It processes text, image, and audio inputs to generate text outputs, supporting a 128K token context length. Enhanced via SFT, DPO, and RLHF for instruction following and safety.",
  "release_date": "2025-02-01",
  "announcement_date": "2025-02-01",
  "license_id": "mit",
  "multimodal": true,
  "knowledge_cutoff": "2024-06-01",
  "param_count": 5600000000,
  "training_tokens": 5000000000000,
  "available_in_zeroeval": true,
  "source_api_ref": null,
  "source_playground": "https://ai.azure.com/explore/models?selectedCollection=phi&tid=72f988bf-86f1-41af-91ab-2d7cd011db47",
  "source_paper": "https://arxiv.org/abs/2503.01743",
  "source_scorecard_blog_link": "https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/",
  "source_repo_link": null,
  "source_weights_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
  "created_at": "2025-07-19T19:49:05.571307+00:00",
  "updated_at": "2025-07-19T19:49:05.571307+00:00",
  "model_family_id": null
}