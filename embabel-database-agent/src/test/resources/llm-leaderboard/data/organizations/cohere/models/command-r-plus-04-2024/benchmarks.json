[
  {
    "model_benchmark_id": 1,
    "benchmark_id": "arc-c",
    "model_id": "command-r-plus-04-2024",
    "score": 0.7099,
    "normalized_score": 0.7099,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "verified_by_llmstats": false,
    "analysis_method": "Standardized Evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.062949+00:00",
    "updated_at": "2025-07-19T19:56:11.062949+00:00",
    "benchmark_name": "ARC-C"
  },
  {
    "model_benchmark_id": 157,
    "benchmark_id": "gsm8k",
    "model_id": "command-r-plus-04-2024",
    "score": 0.707,
    "normalized_score": 0.707,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "verified_by_llmstats": false,
    "analysis_method": "Standardized Evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.401017+00:00",
    "updated_at": "2025-07-19T19:56:11.401017+00:00",
    "benchmark_name": "GSM8k"
  },
  {
    "model_benchmark_id": 32,
    "benchmark_id": "hellaswag",
    "model_id": "command-r-plus-04-2024",
    "score": 0.886,
    "normalized_score": 0.886,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "verified_by_llmstats": false,
    "analysis_method": "Standardized Evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.149067+00:00",
    "updated_at": "2025-07-19T19:56:11.149067+00:00",
    "benchmark_name": "HellaSwag"
  },
  {
    "model_benchmark_id": 56,
    "benchmark_id": "mmlu",
    "model_id": "command-r-plus-04-2024",
    "score": 0.757,
    "normalized_score": 0.757,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "verified_by_llmstats": false,
    "analysis_method": "Standardized Evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.202939+00:00",
    "updated_at": "2025-07-19T19:56:11.202939+00:00",
    "benchmark_name": "MMLU"
  },
  {
    "model_benchmark_id": 131,
    "benchmark_id": "truthfulqa",
    "model_id": "command-r-plus-04-2024",
    "score": 0.563,
    "normalized_score": 0.563,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "verified_by_llmstats": false,
    "analysis_method": "Standardized Evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.341733+00:00",
    "updated_at": "2025-07-19T19:56:11.341733+00:00",
    "benchmark_name": "TruthfulQA"
  },
  {
    "model_benchmark_id": 147,
    "benchmark_id": "winogrande",
    "model_id": "command-r-plus-04-2024",
    "score": 0.854,
    "normalized_score": 0.854,
    "is_self_reported": true,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "verified_by_llmstats": false,
    "analysis_method": "Standardized Evaluation",
    "verification_provider_id": null,
    "verification_hardware": null,
    "verification_date": null,
    "verification_notes": null,
    "created_at": "2025-07-19T19:56:11.378573+00:00",
    "updated_at": "2025-07-19T19:56:11.378573+00:00",
    "benchmark_name": "Winogrande"
  }
]