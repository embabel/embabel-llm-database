{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "Llama 3.1 Nemotron Nano 8B V1",
  "description": "Llama-3.1-Nemotron-Nano-8B-v1 is a large language model (LLM) which is a derivative of Meta Llama-3.1-8B-Instruct (AKA the reference model). It is a reasoning model that is post trained for reasoning, human chat preferences, and tasks, such as RAG and tool calling.",
  "release_date": "2025-03-18",
  "input_context_size": 131072,
  "output_context_size": 131072,
  "license": "Llama 3.1 Community License",
  "multimodal": false,
  "web_hydrated": false,
  "knowledge_cutoff": "2023-12-31",
  "api_ref_link": null,
  "playground_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1",
  "paper_link": "https://arxiv.org/abs/2502.00203",
  "scorecard_blog_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
  "repo_link": null,
  "weights_link": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
  "param_count": 8000000000,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "MT-Bench",
      "score": 0.81,
      "is_self_reported": true,
      "analysis_method": "Score, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    },
    {
      "dataset_name": "MATH-500",
      "score": 0.954,
      "is_self_reported": true,
      "analysis_method": "Pass@1, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    },
    {
      "dataset_name": "AIME 2025",
      "score": 0.471,
      "is_self_reported": true,
      "analysis_method": "Pass@1, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.541,
      "is_self_reported": true,
      "analysis_method": "Diamond, Pass@1, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    },
    {
      "dataset_name": "IFEval",
      "score": 0.793,
      "is_self_reported": true,
      "analysis_method": "Strict Accuracy, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    },
    {
      "dataset_name": "BFCL v2",
      "score": 0.636,
      "is_self_reported": true,
      "analysis_method": "Score, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    },
    {
      "dataset_name": "MBPP",
      "score": 0.846,
      "is_self_reported": true,
      "analysis_method": "0-shot, Pass@1, Reasoning",
      "date_recorded": "2025-03-01",
      "source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard"
    }
  ]
}
